+++
title = "The relationships between oral language and reading instruction: Evidence from a computational model of reading"
date = 2019-12-01T22:55:27+01:00
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["**Ya-Ning Chang**", "J. S. H. Taylor", "Kathleen Rastle", "Padraic Monaghan"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["3"]

# Publication name and optional abbreviated version.
publication = "*PsyArxiv*"
publication_short = ""

# Abstract and optional shortened version.
abstract = "To become a proficient reader, children must learn mappings between print, sound and meaning. Using learning of artificial orthographies, studies have compared print-to-sound or print-to-meaning focused reading training and demonstrated that print-to-sound training is superior for learning to read. However, the extent to which this advantage is dependent on prior acquisition of effective oral language skills remains unclear. To explore this issue, we developed a series of computational models of reading incorporating orthographic, phonological and semantic processing to simulate both artificial and natural orthographic learning conditions in adults and children. We exposed the models to sound- or meaning-focused reading training, but tested the influence of the modelsâ€™ oral language proficiency on the effectiveness of these training regimes. Overall, the simulations showed that oral language skills are a key determinant of the behavioural advantage of print-to-sound focused reading training. The results emphasise that early reading training should address development of both oral language skills and print-to-sound mappings."
abstract_short = ""

# Is this a featured publication? (true/false)
featured = false

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Slides (optional).
#   Associate this page with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = []

# Links (optional).
url_pdf = ""
url_preprint = "10.31234/osf.io/tny9k"
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Digital Object Identifier (DOI)
doi = ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = ""
+++
